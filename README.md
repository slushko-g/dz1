В работе использован датасет Rain in Australia (прогноз дождя на следующий день, целевая переменная RainTomorrow). Я выбрал этот датасет, потому что он близок к реальной постановке: есть пропуски, смешанные типы признаков (числовые + категориальные), потенциальный дисбаланс классов.

Файл данных: weatherAUS.csv (https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package).

Гипотезы:

Циклическое кодирование месяца улучшит качество по сравнению с удалением даты, так как дождь имеет сезонность.

Циклическое кодирование направления ветра (sin/cos) будет лучше, чем использование “угла как числа”, так как направление — циклическая величина, и 0° близко к 360°.

Логистическая регрессия даст стабильное качество на CV (малый разброс по фолдам), так как линейная модель с регуляризацией менее склонна к переобучению.

Неограниченное дерево решений переобучится (высокий train-score и низкий CV-score), особенно после OHE категориальных признаков.

Регуляризация дерева через ограничения глубины/размеров листьев уменьшит переобучение и улучшит CV-качество по сравнению с baseline деревом.

Добавление Location через OHE улучшит качество, так как география влияет на климат

Корректная обработка пропусков через импутацию внутри Pipeline даст лучшее качество, чем удаление строк с пропусками, так как удаление приводит к сильной потере данных и смещению выборки.

Краткие результаты

Подготовка признаков:

из Date извлечён месяц и закодирован через month_sin/month_cos;

направления ветра (WindGustDir, WindDir9am, WindDir3pm) переведены в угол и закодированы через sin/cos

для числовых признаков использована импутация медианой + индикаторы пропусков (add_indicator=True)

для категорий (Location, RainToday) использованы импутация модой и One-Hot Encoding

Логистическая регрессия (baseline, StratifiedKFold=5) показала стабильные результаты

ROC-AUC = 0.874 ± 0.002

PR-AUC = 0.704 ± 0.004

F1 = 0.633 ± 0.003

Recall = 0.782 ± 0.004

Precision = 0.531 ± 0.002

Дерево решений без ограничений сильно переобучилось:

train метрики ≈ 1.000

на CV качество заметно ниже (например PR-AUC около 0.395), что подтверждает гипотезу о высокой variance.

Подбор гиперпараметров для дерева решений (ограничение max_depth, min_samples_leaf, min_samples_split) существенно улучшило результаты на CV и уменьшило train–test метрики:

лучшие из ручных настроек дали PR-AUC до 0.663 и ROC-AUC до 0.851 (train близок к test), но модель всё ещё уступает логистической регрессии по PR-AUC/ROC-AUC.

Итого по гипотезам:

(3) подтверждена: логистическая регрессия стабильна (малый std по фолдам).

(4) подтверждена: неограниченное дерево переобучается.

(5) подтверждена: ограничения на дерево улучшают CV и снижают переобучение.

(1), (2), (6), (7) были реализованы на уровне feature engineering и пайплайнов; в рамках дедлайна полный grid search и отдельные абляции по всем пунктам выполнить не успел, поэтому эти гипотезы можно считать частично проверенными (признаки добавлены и использованы, но сравнения “включено vs выключено” не доведены до конца).
